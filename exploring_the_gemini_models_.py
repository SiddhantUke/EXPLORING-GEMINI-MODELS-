# -*- coding: utf-8 -*-
"""Exploring the Gemini  Models .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VkFvJCGDC6oj4vaSfPTba82265gfpqcl
"""



"""---




#`The demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. `


---


1. Set up your development environment and API access to use Gemini.
2. Generate text responses from text inputs.
3. Generate text responses from multimodal inputs (text and images).
4. Use Gemini for multi-turn conversations (chat).
5. Use embeddings for large language models.

##INSTALL THE PYTHON SDK

---



The Python SDK for the Gemini API, is contained in the `google-generativeai package`. Install the dependency using pip:



---

Responsible for calling various Gemini Models.
"""

!pip install -q -U google_generativeai

import pathlib
import textwrap
import google.generativeai as genai

from IPython.display import display
from IPython.display import Markdown

def to_markdown(text):
  text = text.replace('.','  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

"""

---


 ## In Order to Call `API key` We need to set `API KEY`.

---


"""

from google.colab import  userdata

"""---




Once you have the `API` key, pass it to the SDK. You can do this in two ways:


 Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there)

 1) Pass the key to genai.configure(api_key=...)

 2) Use os.getenv('GOOGLE_API_KEY') to fetch an environment variable



---

`SETUP THE API KEY `
"""

GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)



"""## EXPLORING THE MODEL OF GEMINI MODEL

"""

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)



"""### gemini-pro: optimized for text-only prompts.

### gemini-pro-vision: optimized for text-and-images prompts.

#CALLING THE MODEL
"""

model = genai.GenerativeModel('models/gemini-1.5-pro')

model

# Commented out IPython magic to ensure Python compatibility.
# %time

response = model.generate_content("Who is Goku?")

response.text

to_markdown(response.text)

response.prompt_feedback

# Commented out IPython magic to ensure Python compatibility.
# %time

response = model.generate_content("Who is Goku?" , stream = True )



"""---


`DISPLAYING THE TEXT CHUNK BY CHUNK`

---

### PARTS BY PARTS ALL RESPONSE ARE VISIBLE NOW.
"""

for chunk in response :
  print (chunk.text)
  print("_"*80)



"""### `GENERATE TEXT FROM IMAGE AND TEXT INPUTS `

Gemini provides a multimodal model(gemini-pro-vision) that accepts both text and images and inputs.


The Generative Model.generate_content API is designed to handle multimodal prompts and returns a text output
"""

!curl -o image.jpg https://the7eagles.com/wp-content/uploads/2024/05/What-is-an-Image-URL.webp

import PIL.Image

img = PIL.Image.open("image.jpg")
img

model = genai.GenerativeModel('gemini-1.5-flash')

response = model.generate_content(img)

to_markdown(response.text)

response = model.generate_content(["write a short, engaging blog post based on this picture ", img ], stream = True)

response.resolve()

to_markdown(response.text)

! apt-get install git



!git clone https://github.com/SiddhantUke/EXPLORING-GEMINI-MODELS-.git